{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f765cfe6",
   "metadata": {},
   "source": [
    "# Time Series walkthrough\n",
    "\n",
    "In order to inform the bed allocation process we developed a demand predictor to forecast the number of patients due to be admitted into the hospital. We adopted a Bayesian modelling approach using numpryo and jax. The fundamental idea behind this approach is that the model itself is considered to be a statistical object. In particular, the model parameters that define the model are interpreted as being drawn from a distribution defined using Bayesâ€™ Theorem. The output to the model is then a full posterior distribution for the predicted number of admissions rather than a single number. This allows us to draw samples for the predicted number of admissions and generate confidence intervals over our estimates.\n",
    "\n",
    "The admissions forecast model consisted of four components which account for: \n",
    "- The long term trend: to account for variations such as the current rise in admissions after the downturn during COVID-19 lockdowns; \n",
    "- The day of the week: to account for variations connected with specific days in the week, e.g. admissions are typically lower on the weekends; \n",
    "- The hour of the day: to account for variations connected with the time of day, e.g. fewer patients are admitted at night than during the day; \n",
    "- Whether it is a bank holiday: to account for variations that are due to these specific dates, e.g. fewer patients are admitted on bank holidays.\n",
    "\n",
    "We captured the long term trend in the historic admissions data using a Gaussian Process (GP), inspired by previous work of Vehtari et al., as summarised in this [blog post](https://avehtari.github.io/casestudies/Birthdays/birthdays.html#Model_3:_Slow_trend_+_yearly_seasonal_trend_+_day_of_week). A GP does not constrain the model to take on any particular form. Instead, it returns a distribution over the functions which are consistent with the observed data, in this case, the historic admissions timeseries. In practice, exact GPs can be inefficient to calculate, we therefore utilised the Hilbert Space approximation based on [this numpyro tutorial](http://num.pyro.ai/en/latest/examples/hsgp.html) to ensure tractable runtimes.\n",
    "\n",
    "## 1. Import required modules\n",
    "\n",
    "_Note:_ you will need to first install the module as per the instructions in the main README, and run a notebook server from within the same virtual environment to have access to the `hospital` submodules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ada0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from forecasting.forecast import PatientForecast\n",
    "from forecasting.utils import (\n",
    "    FORECAST_HOURS, # 24\n",
    "    HISTORIC_HOURS, # 168 \n",
    "    HOURS_IN_WEEK, # 168 \n",
    "    START_FORECAST, # 01/05/1855 00:00\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34d22a",
   "metadata": {},
   "source": [
    "## 2. Initialise forecast class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise class\n",
    "forecast_model = PatientForecast()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a44f9",
   "metadata": {},
   "source": [
    "## 3. Train model\n",
    "\n",
    "We trained the model on previous admissions data, aggregated to show the total number of admissions (medical and surgical) every hour for the past 120 days. We chose this as our training period because it allows enough time for both the short and long term trends to show up within the data, whilst reducing the effect of the abnormalities in admission caused by COVID-19. Once the model has been trained, we can then use it to predict the number of patients that will be admitted each hour. Rather than a single number, the demand predictor produces a posterior distribution, meaning we can draw samples for the predicted number of patient admissions. We can also use the posterior to generate confidence intervals for our model. Here we use the 95% confidence interval, which means that 95 times out of 100 we expect the patient admission numbers to fall within the range provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, with training period ending at START_FORECAST\n",
    "forecast_model.train_model(START_FORECAST, training_hours=2880)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e9475",
   "metadata": {},
   "source": [
    "## 4. Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213146b1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get prediction for 1 week before START_FORECAST and 24hrs after a week after START_FORECAST\n",
    "results = forecast_model.call_forecast(\n",
    "    START_FORECAST,\n",
    "    historic_hours=HISTORIC_HOURS,\n",
    "    forecast_hours=HOURS_IN_WEEK + FORECAST_HOURS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246dd593",
   "metadata": {},
   "source": [
    "## 5. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results, open(\"../data/forecast_results.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfa7905",
   "metadata": {},
   "source": [
    "## 6. Validate model\n",
    "\n",
    "In order to check the performance of the demand predictor, we need to validate the predictions against historic admissions data. We can do this by training the model on historic patient admissions data, for example on the 120 days between 01/01/2021 and 30/04/2021. We then generate a forecast for the next 7 days, in this example between 01/05/2021 and 07/05/2021, and compare it to historic data from that time period. We can look at where the admitted number of patients for each hour lies compared to different confidence intervals and check that the correct amount of historic data lies within each confidence interval, for example 50% of the actual patients that arrived should fall within the 50% confidence interval predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "from jax import random\n",
    "from numpyro.infer import MCMC, NUTS, Predictive, init_to_median \n",
    "from collections import defaultdict\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from forecasting.time_series_model import gp\n",
    "from forecasting.forecast import UnivariateScaler\n",
    "from forecasting.utils import load_timeseries, load_holidays \n",
    "from forecasting.plotting import ribbon_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16b82e",
   "metadata": {},
   "source": [
    "### 6.1 Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPUS = int(os.environ.get(\"NUM_CPUS\", os.cpu_count()))\n",
    "numpyro.set_host_device_count(NUM_CPUS)\n",
    "\n",
    "# Set a random seed\n",
    "rng_key = random.PRNGKey(42)\n",
    "\n",
    "# Load holiday data\n",
    "HOLIDAYS = load_holidays()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e3146a",
   "metadata": {},
   "source": [
    "### 6.2 Define validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation class\n",
    "class Validation:\n",
    "    COVID_START_DATE = pd.to_datetime(\"2020-Mar-20\")\n",
    "\n",
    "    def __init__(self, mcmc, training_hours=2880, forecast_hours=168):\n",
    "        self.training_hours = training_hours\n",
    "        self.forecast_hours = forecast_hours\n",
    "        self.timeseries = load_timeseries()\n",
    "        self.mcmc = mcmc\n",
    "        # These are instantiated at training time \n",
    "        self.x_scaler = None\n",
    "        self.L = None\n",
    "        self.training_start_date = None\n",
    "\n",
    "    def run(self, rng_key, dates):\n",
    "        subkeys = jax.random.split(rng_key, num=len(dates)) \n",
    "        results = {}\n",
    "        for key, date in zip(subkeys, dates):\n",
    "            y_train, y_test = self.split(date)\n",
    "            training_data = self.prepare_data_dictionary(y_train, is_training=True)\n",
    "            forecast_data = self.prepare_data_dictionary(y_test, is_training=False)\n",
    "            self.mcmc.run(key, **training_data)\n",
    "            prediction = self.predict(key, **forecast_data)\n",
    "            results[date] = (y_test, prediction, mcmc.get_samples())\n",
    "        return results\n",
    "\n",
    "    def predict(self, rng_key, *args, **kwargs):\n",
    "        predictive = Predictive(self.mcmc.sampler.model, posterior_samples=self.mcmc.get_samples())\n",
    "        prediction = predictive(rng_key, *args, **kwargs)\n",
    "        return prediction[\"y\"]\n",
    "\n",
    "    def split(self, date, validate=True):\n",
    "        self._validate_split_date(date)\n",
    "        past_datetimes = self.timeseries.loc[:date].index\n",
    "        future_datetimes = self.timeseries.index.difference(past_datetimes) \n",
    "        training_datetimes = past_datetimes[-self.training_hours:] \n",
    "        forecast_datetimes = future_datetimes[:self.forecast_hours]\n",
    "        y_train = self.timeseries.loc[training_datetimes]\n",
    "        y_test = self.timeseries.loc[forecast_datetimes]\n",
    "        return y_train, y_test\n",
    "\n",
    "    def prepare_data_dictionary(self, y, is_training=True): \n",
    "        if is_training:\n",
    "            # Reset the scaler in each training, re-use if validating\n",
    "            self.x_scaler = UnivariateScaler()\n",
    "            self.training_start_date = y.index.min()\n",
    "        \n",
    "        x = (y.index - self.training_start_date) / pd.Timedelta(\"1H\")\n",
    "        xsd = self.x_scaler.fit_transform(x)\n",
    "        \n",
    "        if is_training:\n",
    "            self.L = 1.5 * max(xsd)\n",
    "        \n",
    "        day_of_week = y.index.day_of_week\n",
    "        hour_of_day = y.index.hour\n",
    "        is_holiday = [d.date() in HOLIDAYS.date for d in y.index]\n",
    "        return {\n",
    "            \"y\": jnp.array(y.values) if is_training else None, \n",
    "            \"x\": jnp.array(xsd),\n",
    "            \"day_of_week\": jnp.array(day_of_week), \n",
    "            \"hour_of_day\": jnp.array(hour_of_day), \n",
    "            \"is_holiday\": jnp.array(is_holiday),\n",
    "            \"L\": self.L,\n",
    "            \"M\": 10,\n",
    "        }\n",
    "\n",
    "    def _validate_split_date(self, date): \n",
    "        \"\"\"\n",
    "        Do not split if Covid is very recently in the past or in the very near future. \"\"\"\n",
    "        if date >= self.COVID_START_DATE:\n",
    "            dt_past = (date - self.COVID_START_DATE) / pd.Timedelta(\"1H\")\n",
    "            dt_future = (self.timeseries.index.max() - date) / pd.Timedelta(\"1H\")\n",
    "        \n",
    "            msg1 = (\n",
    "            f\"At least {self.training_hours} training hours are required\" f\" but it's only been {dt_past} hours since Covid started\"\n",
    "            )\n",
    "            msg2 = (\n",
    "            f\"At least {self.forecast_hours} validation hours are required\" f\" but there's only {dt_future} hours left in the future.\"\n",
    "            )\n",
    "            assert (dt_past > self.training_hours), msg1 \n",
    "            assert (dt_future > self.forecast_hours), msg2\n",
    "        else:\n",
    "            dt_future = (self.COVID_START_DATE - date) / pd.Timedelta(\"1H\") \n",
    "            dt_past = (date - self.timeseries.index.min()) / pd.Timedelta(\"1H\") \n",
    "            msg1 = (\n",
    "                f\"At least {self.forecast_hours} validation hours are required\"\n",
    "                f\" but there's only {dt_future} hours until Covid starts.\" )\n",
    "            msg2 = (\n",
    "                f\"At least {self.training_hours} training hours are required\" \n",
    "                f\" but it's only been {dt_past} hours since data collection started\" )\n",
    "            assert (dt_future > self.forecast_hours), msg1 \n",
    "            assert (dt_past > self.training_hours), msg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89614aca",
   "metadata": {},
   "source": [
    "### 6.3 Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = MCMC(NUTS(gp, init_strategy=init_to_median), num_warmup=2000, num_samples=2000, num_chains=4)\n",
    "\n",
    "# Initalise class instance\n",
    "cv = Validation(mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884b25a",
   "metadata": {},
   "source": [
    "### 6.4 Select validation dates\n",
    "\n",
    "We chose 20 random dates during the period that we have data for (01/07/2016 - 01/07/2021) to perform validation on. For each of these 20 dates, we checked that there was sufficient data before that date to train the model (120 days) and sufficient data after that date to validate the model (7 days). We also checked for each of the dates the training and validation periods did not overlap with the start of the COVID-19 pandemic (defined for this purpose as 20/03/2020). The reason that we did not extensively test this modelâ€™s performance over the pandemic period is that this model was not designed to predict the sudden drop in planned admissions and rise of COVID-19 admissions caused by the pandemic. For modelling admissions during COVID-19 a different functional form is recommended, such as the epidemiologically inspired approach adopted in the Early Warning System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 20 random dates to perform validation\n",
    "selected_dates = pd.to_datetime(sorted(np.random.choice(cv.timeseries.index,size=20, replace=False)))\n",
    "selected_dates = list(selected_dates)\n",
    "selected_dates\n",
    "\n",
    "# Test if any of these dates are too close to start of COVID\n",
    "validation_dates = []\n",
    "for date in selected_dates:\n",
    "    try: \n",
    "        cv.split(date)\n",
    "    except AssertionError: \n",
    "        print(f\"skipping {date}\") \n",
    "        continue\n",
    "    else: \n",
    "        validation_dates.append(date)\n",
    "\n",
    "validation_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b04a7e9",
   "metadata": {},
   "source": [
    "### 6.5 Run validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random key generator\n",
    "cv_rng_key = jax.random.PRNGKey(1)\n",
    "\n",
    "# Run validation\n",
    "result = cv.run(cv_rng_key, validation_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306eabff",
   "metadata": {},
   "source": [
    "### 6.6 Plot forecast for validation dates\n",
    "\n",
    "The figure below shows the validation plots on different dates, with the date for each plot given in the title and shown in the plot as a black dashed line. In each of these plots, the blue points show a subset of the 120 days worth of training data before each date, and the grey points are 7 days worth of validation data after each date, with the training and validation data both having come from the data provided to us by KGH. The coral bands then show the 95% confidence intervals for the model. The day of the week and hour of the day effects are evident within these plots, as you can see the drop in admissions on weekends and during the night. The effect of the long term trend is also evident, as the forecast reflects the drop in admissions after COVID compared to before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d9b886",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plot forecast with validation data for each date\n",
    "ax_date_format = mdates.DateFormatter('%b %d\\n%A')\n",
    "f, axes = plt.subplots(len(validation_dates) // 2, 2, figsize=(22,len(validation_dates) * 5 // 2))\n",
    "for ax, date in zip(axes.flatten(), validation_dates):\n",
    "    y_train, _ = cv.split(date, validate=False)\n",
    "    y, forecast, _ = result[date]\n",
    "    ax.plot(y_train.iloc[-400:], marker='o', lw=0, label='Training data') \n",
    "    ax.plot(y, marker='o', lw=0, color='k', alpha=0.5, label='Validation data') \n",
    "    ax.vlines(date, 0, max(y)+1, color='black', linestyles='dashed') \n",
    "    ribbon_plot(y.index, forecast, plot_median=False, ax=ax,ribbon_color='coral')\n",
    "    ax.xaxis.set_major_formatter(ax_date_format) \n",
    "    ax.set_title(f\"Validation date: {date: %d/%m/%Y at %H:%M}\") \n",
    "    ax.legend()\n",
    "    ax.set_xlim([min(y_train.iloc[-400:].index), max(y.index)]) \n",
    "    ax.set_ylabel(\"Hospital admissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948ea97",
   "metadata": {},
   "source": [
    "### 6.7 Model calibration\n",
    "\n",
    "To get a measure of how well our model is performing, we can generate plots to show where the validation data points land relative to the confidence intervals from the forecast, such as the one in the figure below. For example, if a validation data point was right in the centre of the forecast band it would be placed on percentile 50 in this plot. The x axis then shows the time in hours between the validation data point and the date the validation was performed on. For a perfect model, 50% of the points would lie within the darkest coral band, 80% within the next band and then 95% within the lightest band. The figure at the bottom shows the results of this test - 48%, 78% and 94% of the validation points fall within the 50%, 80% and 95% confidence intervals respectively. In summary, the results of these tests show that our demand predictor is incredibly accurate and provides the users with a reliable indication of incoming patient demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where each validation data point lies compared to percentiles from forecast\n",
    "percentiles = defaultdict(list)\n",
    "for y, forecast, _ in result.values(): \n",
    "    for n, val in enumerate(y.values):\n",
    "        percentiles[n].append(percentileofscore(forecast[:, n], val))\n",
    "\n",
    " # Plots validation data points together compared to which percentile they on\n",
    "plt.figure(figsize=(15, 7))\n",
    "for n, ps in percentiles.items():\n",
    "    plt.plot([n] * len(ps), ps, marker='o', lw=0, color='k', alpha=0.6)\n",
    "plt.axhspan(2.5, 97.5, alpha=0.2, color='coral')\n",
    "plt.axhspan(10, 90, alpha=0.2, color='coral')\n",
    "plt.axhspan(25, 75, alpha=0.2, color='coral')\n",
    "plt.title(\"Confidence interval spread\")\n",
    "plt.xlabel(\"Number of timesteps into the future\")\n",
    "plt.ylabel(\"Percentile\")\n",
    "plt.xlim([0, 168])\n",
    "plt.show()\n",
    "\n",
    "# For each calibration data points, checks whether it is within the 50%, 80% and 95% confidence intervals\n",
    "calibration = {50: [], 80: [], 95: []} \n",
    "for n, ps in percentiles.items():\n",
    "    calibration[50].extend([25 <= val <= 75 for val in ps])\n",
    "    calibration[80].extend([10 <= val <= 90 for val in ps])\n",
    "    calibration[95].extend([2.5 <= val <= 97.5 for val in ps])\n",
    "\n",
    " # Percentage of validation data points within 50%, 80% and 95% confidence intervals respectively\n",
    "sum(calibration[50]) / len(calibration[50]), sum(calibration[80]) / len(calibration[80]), sum(calibration[95]) / len(calibration[95])\n",
    "\n",
    " # Plots amount of validation data points within 50%, 80% and 95% confidence intervals\n",
    "plt.title(\"Confidence intervals coverage\")\n",
    "plt.bar([1, 2, 3], [np.mean(c) for c in calibration.values()], label='Observed', color='coral', alpha=0.7) \n",
    "plt.xticks([1, 2, 3], [\"50%\", \"80%\", \"95%\"]) \n",
    "plt.yticks([0.50, 0.80, 0.95], [\"50%\", \"80%\", \"95%\"]) \n",
    "for p in [50, 80, 95]:\n",
    "    plt.axhline(y=p/100, linestyle=':', color='k', alpha=0.8)\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf3acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
